{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8301214b",
   "metadata": {},
   "source": [
    "# üéØ Pumpfun Kaggle ‚Äî Plan & Starter Code (CatBoost Pipeline)\n",
    "\n",
    "Ce document te donne un **plan d‚Äôattaque clair** et un **d√©but de code** pr√™t √† adapter pour le challenge *Alpha Radar: Solana Sprint* (Pumpfun/Solana), avec **CatBoost**, **feature engineering limit√© aux 30 premi√®res secondes**, **optimisation du Jaccard** et **contrainte Recall ‚â• 75%**.\n",
    "\n",
    "---\n",
    "\n",
    "## 1) Plan d‚Äôattaque (haut niveau)\n",
    "\n",
    "1. **Ingestion & contraintes**\n",
    "\n",
    "   * Charger les CSV de transactions (30s) et la liste des cibles (target tokens).\n",
    "   * **Cl√©**: `mint_token_id`. Fen√™tre d‚Äôanalyse **0‚Äì30 s** post-mint.\n",
    "   * **Soumission**: exactement **64‚ÄØ208** lignes (maj oct. 2025), binaire `{0,1}`.\n",
    "\n",
    "2. **V√©rifs de base**\n",
    "\n",
    "   * Types/dtypes, valeurs manquantes, domaines (`trade_mode` ‚àà {buy, sell, other}).\n",
    "   * Distribution de `is_target` (d√©s√©quilibre attendu).\n",
    "\n",
    "3. **Feature engineering (par token, dans 0‚Äì30 s)**\n",
    "\n",
    "   * **Activit√©/flux**: `buy_count`, `sell_count`, `total_count`, `buy_sell_ratio`.\n",
    "   * **Volumes**: `token_volume`, `sol_volume`, `liquidity_ratio`, `market_cap_usd` (stats: sum/mean/max/std, CV).\n",
    "   * **Prix/techniques**: `relative_strength_index`, `bollinger_relative_position`, `volume_oscillator`, `rate_of_change`, `money_flow_index` (mean/max/std, trending: derni√®re valeur vs moyenne).\n",
    "   * **R√©serves pool**: `virtual_sol_reserves`, `virtual_token_reserves` (mean/max, ratio).\n",
    "   * **Comportements acteurs**: `total_holders`, `current_holders`, `holder_ratio`, diversit√© acheteurs (approx via `current_holders/total_holders`).\n",
    "   * **Cr√©ateur**: `creator_fee`, `creator_fee_pump`, `creator_balance`, `creator_sold`, indicateurs `creator_activity` (a vendu ? a un gros solde ? ratio `creator_sold/token_volume`).\n",
    "   * **Gas/Frais**: `consumed_gas` (mean/sum/max), `fee` (mean/max), proxy d‚Äôurgence/network friction.\n",
    "   * **Deltas**: `token_delta`, `sol_delta` (sum/sign, ratios au volume).\n",
    "   * **Temporalit√© intra-30s**: features **early vs late** (ex: stats sur [0‚Äì10s], [10‚Äì20s], [20‚Äì30s]) si le dataset contient un horodatage assez fin.\n",
    "\n",
    "4. **Agr√©gation ‚Üí 1 ligne/token**\n",
    "\n",
    "   * `groupby(mint_token_id)` pour produire la matrice finale X (une ligne par token).\n",
    "\n",
    "5. **Labellisation**\n",
    "\n",
    "   * Joindre la liste `target_tokens` ‚Üí `is_target ‚àà {0,1}`.\n",
    "\n",
    "6. **Split & Validation**\n",
    "\n",
    "   * Split **stratifi√© par `is_target`** (ex: 80/20). Option *time-aware* si on veut √©viter fuite temporelle (train sur d√©but du mois, val sur fin).\n",
    "\n",
    "7. **CatBoost**\n",
    "\n",
    "   * Gestion d√©s√©quilibre: `class_weights` ou `scale_pos_weight`.\n",
    "   * `eval_metric='Logloss'` + `use_best_model=True` (early stopping).\n",
    "   * Seed fixe pour reproductibilit√©.\n",
    "\n",
    "8. **Seuil optimis√© Jaccard (avec contrainte Recall ‚â• 0.75)**\n",
    "\n",
    "   * Balayer `threshold ‚àà [0,1]`.\n",
    "   * Pour chaque seuil: calculer `TP, FP, FN`, **Recall** et **Jaccard**.\n",
    "   * Choisir le **seuil max Jaccard** **sous la contrainte** `Recall ‚â• 0.75`.\n",
    "\n",
    "9. **√âvaluation & Rapport**\n",
    "\n",
    "   * Afficher **Jaccard**, **Recall**, **Pr√©cision**, **F1**.\n",
    "   * Matrice de confusion + \"**confusion Jaccard**\" (TP/(TP+FP+FN)).\n",
    "\n",
    "10. **Soumission**\n",
    "\n",
    "    * Pr√©dire sur l‚Äô**√©val set** ‚Üí `mint_token_id,is_target` (binaire via seuil choisi).\n",
    "    * **V√©rifier**: exactement **64‚ÄØ208** lignes + **header**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ade17df",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# CatBoost\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier, Pool\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Config\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mConfig\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "# pumpfun_pipeline.py\n",
    "\n",
    "\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict, List\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# CatBoost\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    transactions_csv: str = \"C:\\\\Users\\\\tje6d8f\\\\OneDrive - Colruyt Group NV\\\\Bureau\\\\Pers\\\\Alpha radar pumpfun 30sec\\\\Fichiers test\\\\september_2025_first30s_chunk_001\" # √† adapter\n",
    "    targets_csv: str = \"C:\\\\Users\\\\tje6d8f\\\\OneDrive - Colruyt Group NV\\\\Bureau\\\\Pers\\\\Alpha radar pumpfun 30sec\\\\Fichier validation\\\\Validation\" # √† adapter\n",
    "    output_dir: str = \"./outputs\"\n",
    "    random_state: int = 42\n",
    "    test_size: float = 0.2\n",
    "    recall_constraint: float = 0.75\n",
    "    expected_eval_rows: int = 64208 # maj Oct 2025\n",
    "\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "\n",
    "os.makedirs(CFG.output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c8e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Utils m√©triques\n",
    "# -----------------------------\n",
    "\n",
    "def jaccard_score(tp: int, fp: int, fn: int) -> float:\n",
    "    denom = tp + fp + fn\n",
    "    return tp / denom if denom > 0 else 0.0\n",
    "\n",
    "\n",
    "def evaluate_threshold(y_true: np.ndarray, y_prob: np.ndarray, thr: float) -> Dict[str, float]:\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    f1 = 2*precision*recall/(precision+recall) if (precision+recall) > 0 else 0.0\n",
    "    jacc = jaccard_score(tp, fp, fn)\n",
    "    return {\n",
    "        \"threshold\": thr,\n",
    "        \"tp\": tp, \"fp\": fp, \"fn\": fn, \"tn\": tn,\n",
    "        \"recall\": recall, \"precision\": precision, \"f1\": f1, \"jaccard\": jacc\n",
    "    }\n",
    "\n",
    "\n",
    "def best_threshold_under_recall(y_true: np.ndarray, y_prob: np.ndarray, min_recall: float = 0.75) -> Dict[str, float]:\n",
    "    # Balayage fin autour de la zone utile\n",
    "    candidates = np.linspace(0.01, 0.99, 99)\n",
    "    reports = [evaluate_threshold(y_true, y_prob, t) for t in candidates]\n",
    "    feasible = [r for r in reports if r[\"recall\"] >= min_recall]\n",
    "    if not feasible:\n",
    "        # pas de seuil qui respecte la contrainte, on prend celui qui maximise le recall (fallback)\n",
    "        return max(reports, key=lambda r: r[\"recall\"])\n",
    "    return max(feasible, key=lambda r: r[\"jaccard\"])  # maximise Jaccard sous contrainte de recall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef0f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Chargement & dtypes\n",
    "# -----------------------------\n",
    "\n",
    "def dtype_map() -> Dict[str, str]:\n",
    "    return {\n",
    "        \"index\": \"int32\",\n",
    "        \"timestamp\": \"string\",  # pars√© ensuite en datetime si besoin\n",
    "        \"mint_token_id\": \"string\",\n",
    "        \"holder\": \"string\",\n",
    "        \"trade_mode\": \"category\",\n",
    "        \"token_quantity\": \"float32\",\n",
    "        \"creator\": \"string\",\n",
    "        \"creator_fee\": \"float32\",\n",
    "        \"creator_fee_pump\": \"float32\",\n",
    "        \"market_cap_usd\": \"float32\",\n",
    "        \"token_delta\": \"float32\",\n",
    "        \"sol_delta\": \"float32\",\n",
    "        \"buy_count\": \"int16\",\n",
    "        \"sell_count\": \"int16\",\n",
    "        \"total_count\": \"int16\",\n",
    "        \"token_volume\": \"float32\",\n",
    "        \"sol_volume\": \"float32\",\n",
    "        \"liquidity_ratio\": \"float32\",\n",
    "        \"virtual_sol_reserves\": \"float32\",\n",
    "        \"virtual_token_reserves\": \"float32\",\n",
    "        \"consumed_gas\": \"float32\",\n",
    "        \"fee\": \"float32\",\n",
    "        \"relative_strength_index\": \"float32\",\n",
    "        \"bollinger_relative_position\": \"float32\",\n",
    "        \"volume_oscillator\": \"float32\",\n",
    "        \"rate_of_change\": \"float32\",\n",
    "        \"money_flow_index\": \"float32\",\n",
    "        \"total_holders\": \"int32\",\n",
    "        \"current_holders\": \"int32\",\n",
    "        \"top10_percent_total\": \"float32\",\n",
    "        \"creator_balance\": \"float32\",\n",
    "        \"creator_sold\": \"float32\",\n",
    "        \"holder_ratio\": \"float32\",\n",
    "        \"buy_sell_ratio\": \"float32\",\n",
    "    }\n",
    "\n",
    "\n",
    "def load_transactions(path: str) -> pd.DataFrame:\n",
    "    usecols = list(dtype_map().keys())\n",
    "    df = pd.read_csv(path, usecols=usecols, dtype=dtype_map())\n",
    "    # Optionnel: df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True, errors='coerce')\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_targets(path: str) -> pd.DataFrame:\n",
    "    # Suppose un CSV avec une colonne 'mint_token_id' listant les tokens cibles\n",
    "    t = pd.read_csv(path)\n",
    "    # Harmonisation colonnes\n",
    "    col = None\n",
    "    for c in t.columns:\n",
    "        if c.lower() in {\"mint_token_id\", \"token\", \"mint\", \"mint_id\"}:\n",
    "            col = c\n",
    "            break\n",
    "    if col is None:\n",
    "        raise ValueError(\"Impossible de trouver la colonne mint_token_id dans le fichier targets.\")\n",
    "    t = t[[col]].rename(columns={col: \"mint_token_id\"})\n",
    "    t[\"is_target\"] = 1\n",
    "    return t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e38ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Feature engineering (agg par token)\n",
    "# -----------------------------\n",
    "\n",
    "def _agg_stats(series: pd.Series, prefix: str) -> Dict[str, float]:\n",
    "    return {\n",
    "        f\"{prefix}_sum\": series.sum(),\n",
    "        f\"{prefix}_mean\": series.mean(),\n",
    "        f\"{prefix}_max\": series.max(),\n",
    "        f\"{prefix}_std\": series.std(ddof=0),\n",
    "    }\n",
    "\n",
    "\n",
    "def build_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # S√©paration par trade_mode pour quelques compteurs\n",
    "    df[\"is_buy\"] = (df[\"trade_mode\"].astype(\"string\") == \"buy\").astype(\"int8\")\n",
    "    df[\"is_sell\"] = (df[\"trade_mode\"].astype(\"string\") == \"sell\").astype(\"int8\")\n",
    "\n",
    "    groups = []\n",
    "    for token, g in df.groupby(\"mint_token_id\", sort=False):\n",
    "        feats = {\"mint_token_id\": token}\n",
    "\n",
    "        # Comptes bruts (existants mais on les recalcule en s√©curit√©)\n",
    "        feats.update({\n",
    "            \"tx_count\": int(g.shape[0]),\n",
    "            \"buy_count_agg\": int(g[\"is_buy\"].sum()),\n",
    "            \"sell_count_agg\": int(g[\"is_sell\"].sum()),\n",
    "        })\n",
    "        feats[\"buy_sell_ratio_agg\"] = (feats[\"buy_count_agg\"] / max(1, feats[\"sell_count_agg\"]))\n",
    "\n",
    "        # Volumes & deltas\n",
    "        for col in [\n",
    "            \"token_volume\",\"sol_volume\",\"market_cap_usd\",\"liquidity_ratio\",\n",
    "            \"token_delta\",\"sol_delta\",\"consumed_gas\",\"fee\",\n",
    "            \"virtual_sol_reserves\",\"virtual_token_reserves\",\n",
    "            \"relative_strength_index\",\"bollinger_relative_position\",\"volume_oscillator\",\n",
    "            \"rate_of_change\",\"money_flow_index\",\n",
    "        ]:\n",
    "            feats.update(_agg_stats(g[col].astype(\"float32\"), col))\n",
    "\n",
    "        # Holders & cr√©ateur\n",
    "        for col in [\n",
    "            \"total_holders\",\"current_holders\",\"top10_percent_total\",\n",
    "            \"creator_fee\",\"creator_fee_pump\",\"creator_balance\",\"creator_sold\",\n",
    "            \"holder_ratio\",\n",
    "        ]:\n",
    "            # la plupart sont quasi constants sur 30s ‚Üí mean suffit\n",
    "            feats[f\"{col}_mean\"] = g[col].astype(\"float32\").mean()\n",
    "            feats[f\"{col}_max\"] = g[col].astype(\"float32\").max()\n",
    "\n",
    "        # Indicateurs cr√©ateur\n",
    "        feats[\"creator_sold_flag\"] = 1 if (g[\"creator_sold\"].max() > 0) else 0\n",
    "        vol = max(1e-6, g[\"token_volume\"].sum())\n",
    "        feats[\"creator_sell_volume_ratio\"] = float(g[\"creator_sold\"].sum() / vol)\n",
    "\n",
    "        # Diversit√© acheteurs proxy\n",
    "        th = float(g[\"total_holders\"].max()) if not g[\"total_holders\"].isna().all() else 0.0\n",
    "        ch = float(g[\"current_holders\"].max()) if not g[\"current_holders\"].isna().all() else 0.0\n",
    "        feats[\"holder_diversity_ratio_max\"] = (ch / th) if th > 0 else 0.0\n",
    "\n",
    "        groups.append(feats)\n",
    "\n",
    "    feats_df = pd.DataFrame(groups)\n",
    "    feats_df = feats_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    return feats_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e0d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Train / Val\n",
    "# -----------------------------\n",
    "\n",
    "def train_catboost(X: pd.DataFrame, y: pd.Series, cfg: Config = CFG) -> Tuple[CatBoostClassifier, Dict[str, float]]:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=cfg.test_size, stratify=y, random_state=cfg.random_state\n",
    "    )\n",
    "\n",
    "    train_pool = Pool(X_train, y_train)\n",
    "    val_pool = Pool(X_val, y_val)\n",
    "\n",
    "    # Gestion du d√©s√©quilibre: poids inverses de fr√©quence\n",
    "    pos_weight = (len(y_train) - y_train.sum()) / max(1, y_train.sum())\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=2000,\n",
    "        depth=6,\n",
    "        learning_rate=0.03,\n",
    "        loss_function='Logloss',\n",
    "        eval_metric='Logloss',\n",
    "        random_seed=cfg.random_state,\n",
    "        class_weights=[1.0, float(pos_weight)],\n",
    "        verbose=200,\n",
    "        use_best_model=True,\n",
    "        od_type='Iter',\n",
    "        od_wait=200,\n",
    "    )\n",
    "\n",
    "    model.fit(train_pool, eval_set=val_pool)\n",
    "\n",
    "    # Optimisation du seuil (Jaccard sous contrainte Recall)\n",
    "    y_val_prob = model.predict_proba(X_val)[:,1]\n",
    "    report = best_threshold_under_recall(y_val, y_val_prob, cfg.recall_constraint)\n",
    "    return model, report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c80de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Pipeline principal\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    print(\"[1/6] Chargement des donn√©es‚Ä¶\")\n",
    "    df = load_transactions(CFG.transactions_csv)\n",
    "    targets = load_targets(CFG.targets_csv)\n",
    "\n",
    "    print(\"[2/6] Feature engineering (agg par token)‚Ä¶\")\n",
    "    feats = build_features(df)\n",
    "\n",
    "    print(\"[3/6] Jointure labels‚Ä¶\")\n",
    "    data = feats.merge(targets, on=\"mint_token_id\", how=\"left\")\n",
    "    data[\"is_target\"] = data[\"is_target\"].fillna(0).astype(int)\n",
    "\n",
    "    # S√©paration X/y\n",
    "    y = data[\"is_target\"].astype(int)\n",
    "    X = data.drop(columns=[\"is_target\", \"mint_token_id\"])  # garder id √† part pour soumission\n",
    "\n",
    "    print(\"[4/6] Entra√Ænement CatBoost‚Ä¶\")\n",
    "    model, thr_report = train_catboost(X, y)\n",
    "\n",
    "    print(\"Seuil choisi (contrainte recall ‚â• {0:.2f}):\".format(CFG.recall_constraint))\n",
    "    print(json.dumps(thr_report, indent=2))\n",
    "\n",
    "    # Sauvegarde du mod√®le\n",
    "    model_path = os.path.join(CFG.output_dir, \"catboost_model.cbm\")\n",
    "    model.save_model(model_path)\n",
    "    print(f\"Mod√®le sauvegard√©: {model_path}\")\n",
    "\n",
    "    # Exemple de g√©n√©ration soumission (√† adapter √† l'eval set exact de 64,208 rows)\n",
    "    print(\"[5/6] G√©n√©ration soumission‚Ä¶\")\n",
    "    ids = feats[[\"mint_token_id\"]].copy()\n",
    "    probs = model.predict_proba(X)[:,1]\n",
    "    y_pred_bin = (probs >= thr_report[\"threshold\"]).astype(int)\n",
    "\n",
    "    submit = ids.copy()\n",
    "    submit[\"is_target\"] = y_pred_bin\n",
    "\n",
    "    # V√©rif de la contrainte de lignes si on est sur l'eval set officiel\n",
    "    if len(submit) != CFG.expected_eval_rows:\n",
    "        print(f\"[WARN] Lignes soumission = {len(submit)} ‚â† {CFG.expected_eval_rows}. V√©rifie que tu utilises l'eval set.\")\n",
    "\n",
    "    sub_path = os.path.join(CFG.output_dir, \"submission.csv\")\n",
    "    submit.to_csv(sub_path, index=False)\n",
    "    print(f\"Soumission √©crite: {sub_path}\")\n",
    "\n",
    "    # Rapport simple\n",
    "    print(\"[6/6] Rapport validation (local split)‚Ä¶\")\n",
    "    # Re-calcul sur le split val d√©j√† fait dans train_catboost si besoin\n",
    "    # Ici on peut re-√©couter la perf globale train+val pour un ordre de grandeur\n",
    "    # (la perf Kaggle d√©pendra de l'eval set et de la non-fuite de donn√©es)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bb0c58",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3) Pistes d‚Äôam√©lioration (prochaines it√©rations)\n",
    "\n",
    "* **Temporalit√© intra-30s**: fractionner par tranches (0‚Äì10, 10‚Äì20, 20‚Äì30s) et d√©river des *slopes* (diff dernier‚Äìpremier, taux de croissance des volumes/holders, acc√©l√©ration des achats).\n",
    "* **Robustesse anti-faux positifs**: p√©naliser via `class_weights` + seuils plus √©lev√©s si *precision* trop basse, tout en respectant le Recall ‚â• 0.75.\n",
    "* **Validation temporelle**: train sur la premi√®re moiti√© de septembre, val sur la seconde (r√©alisme march√©, √©vite fuite temporelle).\n",
    "* **Features d‚Äô‚Äúint√©grit√© cr√©ateur‚Äù**: gros `creator_balance` + `creator_sold_flag` t√¥t ‚Üí patterns de *rug* potentiels.\n",
    "* **Calibration**: isotonic / Platt (en post-fit) si la calibration am√©liore la recherche du seuil.\n",
    "* **Sanity checks soumission**: d√©dupliquer `mint_token_id`, v√©rifier header, v√©rifier binaire {0,1}, compter exactement **64‚ÄØ208** lignes.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Ce qu‚Äôil te reste √† brancher\n",
    "\n",
    "* Les **chemins fichiers** (`transactions_csv`, `targets_csv`).\n",
    "* La **lecture √©ventuelle par chunks** si ta RAM est serr√©e.\n",
    "* Le **set d‚Äô√©valuation officiel** (pour respecter 64‚ÄØ208 lignes exactement).\n",
    "* √âventuellement, un **notebook Jupyter** qui reprend ce code en cellules + quelques graphiques de distribution.\n",
    "\n",
    "Quand tu as les fichiers, on peut **brancher les chemins**, lancer une **premi√®re passe**, puis **it√©rer sur les features** et l‚Äôoptim du seuil. üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b358f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
